%
% File naaclhlt2018.tex
%
%% Based on the style files for NAACL-HLT 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2018}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}
\usepackage{alltt}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{HMM-HPS: A Heuristic Preseed Approach to Part-of-Speech Tagging with Hidden Markov Models}

\author{Michael Yantosca \\
  Department of Computer Science, University of Houston / Houston, TX \\
  {\tt mike@archivarius.net} \\}

\date{2018-03-04}

\begin{document}
\maketitle
\begin{abstract}
\end{abstract}

\section{Introduction}

\section{Methodology}

Frequency counter for arbitrary order n-gram
Frequency to probability transform
Viterbi decoding
Laplace smoothing -> add-k smoothing on transition and emission probabilities
Heuristic fallback
Rudimentary interpolation, n-gram backoff
Iterative refinement initially testing dev -> dev, then train -> dev
moved to log probabilities
Heuristic preseed
integration of heuristic intuitions earlier in pipeline afforded performance boost in decoding by not having to do heuristic checks all the time (wider feature set)/caveat: probability mass not redistributed in all cases
N-gram weight adjustment
Five submissions to the competition

rapid development prototyping - back of the envelope accuracy measure with diff <1> <2> | egrep '<' | wc -l

\section{Experimental Results}

\begin{alltt}
  $N$ = \$(wc -l dataset/dev.conll)
  $GP$ = \$(egrep '\emph{class}\$' dataset/dev.conll | wc -l)
  $GF$ = $N$ - $GF$
  $FN$ = \$(diff dataset/dev.conll ../hw1-results/dev4.txt | egrep '<' | egrep '\emph{class}\$' | wc -l)
  $FP$ = \$(diff dataset/dev.conll ../hw1-results/dev4.txt | egrep '>' | egrep '\emph{class}\$' | wc -l)
  $TP = GP - FP$
  $TN = GN - FN$
\end{alltt}

problems encountered:
- bugs
- failure to reproduce results with the same exec params
-- first of equiprobable come, first serve
- numerical underflow
- float\_info.min vs. -float\_info.max (relevant when swapping to log prob)

with heuristic fallback vs. without

add-k smoothing (varying k)

backoff vs. rudimentary interpolation

varying n-gram order

\section{Conclusions}

training set too sparse in higher-order n-grams to be of much use
most accurate in 1-grams controlling for other variables until adjusted n-gram weights, at which point higher-order n-grams provided better accuracy (up to 4, then decay?)
decreasing k increased accuracy for dev and test sets, but may not apply in cases with many new unknown vocab
better interpolation, proper selection of lambda factors
better smoothing (i.e., more intelligent distribution of prob mass over unknowns)
lookahead: function of multi-class words often dependent on following context, not only preceding
future work: transfer of language ID to state instead of feature

\section*{Acknowledgments}

Dr. Solorio for heuristic suggestions in lecture (2/28/2018)
NAACL template authors
Jurafsky and Martin for succinctly laying out HMMs in 3rd draft of text

\bibliography{yantosca_COSC6336_assg_1}
\bibliographystyle{acl_natbib}

\appendix

\section{Supplemental Material}
\label{sec:supplemental}

\end{document}
